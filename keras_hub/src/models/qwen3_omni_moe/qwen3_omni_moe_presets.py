"""Qwen3-Omni MoE model presets."""

from keras_hub.src.utils.preset_utils import register_presets

# Qwen3-Omni MoE model presets
backbone_presets = {
    "qwen3_omni_moe_7b": {
        "metadata": {
            "description": "Qwen3-Omni MoE 7B model with multimodal capabilities",
            "parameters": "7B",
            "model_size": "7B",
        },
        "kaggle_handle": "kaggle://keras/qwen3-omni-moe-7b/keras/qwen3_omni_moe_7b",
        "config": {
            "vocabulary_size": 151936,
            "num_layers": 32,
            "num_query_heads": 32,
            "hidden_dim": 4096,
            "intermediate_dim": 11008,
            "num_key_value_heads": 4,
            "rope_max_wavelength": 10000,
            "rope_scaling_factor": 1.0,
            "layer_norm_epsilon": 1e-6,
            "dropout": 0.0,
            "num_experts": 8,
            "num_experts_per_tok": 2,
            "audio_config": {
                "vocab_size": 1024,
                "hidden_size": 4096,
                "num_hidden_layers": 32,
                "num_attention_heads": 32,
                "num_key_value_heads": 4,
                "intermediate_size": 11008,
                "hidden_act": "silu",
                "max_position_embeddings": 32768,
                "initializer_range": 0.02,
                "rms_norm_eps": 1e-6,
                "use_cache": True,
                "rope_theta": 10000.0,
                "rope_scaling": None,
                "attention_bias": False,
                "attention_dropout": 0.0,
                "num_experts": 8,
                "num_experts_per_tok": 2,
                "audio_vocab_size": 1024,
                "audio_hidden_size": 4096,
                "audio_num_hidden_layers": 32,
                "audio_num_attention_heads": 32,
                "audio_num_key_value_heads": 4,
                "audio_intermediate_size": 11008,
                "audio_hidden_act": "silu",
                "audio_max_position_embeddings": 32768,
                "audio_initializer_range": 0.02,
                "audio_rms_norm_eps": 1e-6,
                "audio_use_cache": True,
                "audio_rope_theta": 10000.0,
                "audio_rope_scaling": None,
                "audio_attention_bias": False,
                "audio_attention_dropout": 0.0,
                "audio_num_experts": 8,
                "audio_num_experts_per_tok": 2,
            },
            "vision_config": {
                "hidden_size": 4096,
                "intermediate_size": 11008,
                "num_hidden_layers": 32,
                "num_attention_heads": 32,
                "num_key_value_heads": 4,
                "image_size": 448,
                "patch_size": 14,
                "num_channels": 3,
                "hidden_act": "silu",
                "layer_norm_eps": 1e-6,
                "attention_dropout": 0.0,
                "initializer_range": 0.02,
                "initializer_factor": 1.0,
                "use_cache": True,
                "rope_theta": 10000.0,
                "rope_scaling": None,
                "attention_bias": False,
                "spatial_merge_size": 2,
                "num_experts": 8,
                "num_experts_per_tok": 2,
            },
            "text_config": {
                "vocab_size": 151936,
                "hidden_size": 4096,
                "intermediate_size": 11008,
                "num_hidden_layers": 32,
                "num_attention_heads": 32,
                "num_key_value_heads": 4,
                "hidden_act": "silu",
                "max_position_embeddings": 32768,
                "initializer_range": 0.02,
                "rms_norm_eps": 1e-6,
                "use_cache": True,
                "rope_theta": 10000.0,
                "rope_scaling": None,
                "attention_bias": False,
                "attention_dropout": 0.0,
                "num_experts": 8,
                "num_experts_per_tok": 2,
            },
            "thinker_config": {
                "audio_config": {
                    "vocab_size": 1024,
                    "hidden_size": 4096,
                    "num_hidden_layers": 32,
                    "num_attention_heads": 32,
                    "num_key_value_heads": 4,
                    "intermediate_size": 11008,
                    "hidden_act": "silu",
                    "max_position_embeddings": 32768,
                    "initializer_range": 0.02,
                    "rms_norm_eps": 1e-6,
                    "use_cache": True,
                    "rope_theta": 10000.0,
                    "rope_scaling": None,
                    "attention_bias": False,
                    "attention_dropout": 0.0,
                    "num_experts": 8,
                    "num_experts_per_tok": 2,
                },
                "vision_config": {
                    "hidden_size": 4096,
                    "intermediate_size": 11008,
                    "num_hidden_layers": 32,
                    "num_attention_heads": 32,
                    "num_key_value_heads": 4,
                    "image_size": 448,
                    "patch_size": 14,
                    "num_channels": 3,
                    "hidden_act": "silu",
                    "layer_norm_eps": 1e-6,
                    "attention_dropout": 0.0,
                    "initializer_range": 0.02,
                    "initializer_factor": 1.0,
                    "use_cache": True,
                    "rope_theta": 10000.0,
                    "rope_scaling": None,
                    "attention_bias": False,
                    "spatial_merge_size": 2,
                    "num_experts": 8,
                    "num_experts_per_tok": 2,
                },
                "text_config": {
                    "vocab_size": 151936,
                    "hidden_size": 4096,
                    "intermediate_size": 11008,
                    "num_hidden_layers": 32,
                    "num_attention_heads": 32,
                    "num_key_value_heads": 4,
                    "hidden_act": "silu",
                    "max_position_embeddings": 32768,
                    "initializer_range": 0.02,
                    "rms_norm_eps": 1e-6,
                    "use_cache": True,
                    "rope_theta": 10000.0,
                    "rope_scaling": None,
                    "attention_bias": False,
                    "attention_dropout": 0.0,
                    "num_experts": 8,
                    "num_experts_per_tok": 2,
                },
            },
            "talker_config": {
                "text_config": {
                    "vocab_size": 151936,
                    "hidden_size": 4096,
                    "intermediate_size": 11008,
                    "num_hidden_layers": 32,
                    "num_attention_heads": 32,
                    "num_key_value_heads": 4,
                    "hidden_act": "silu",
                    "max_position_embeddings": 32768,
                    "initializer_range": 0.02,
                    "rms_norm_eps": 1e-6,
                    "use_cache": True,
                    "rope_theta": 10000.0,
                    "rope_scaling": None,
                    "attention_bias": False,
                    "attention_dropout": 0.0,
                    "num_experts": 8,
                    "num_experts_per_tok": 2,
                },
                "code_predictor_config": {
                    "vocab_size": 1024,
                    "hidden_size": 4096,
                    "intermediate_size": 11008,
                    "num_hidden_layers": 32,
                    "num_attention_heads": 32,
                    "num_key_value_heads": 4,
                    "hidden_act": "silu",
                    "max_position_embeddings": 32768,
                    "initializer_range": 0.02,
                    "rms_norm_eps": 1e-6,
                    "use_cache": True,
                    "rope_theta": 10000.0,
                    "rope_scaling": None,
                    "attention_bias": False,
                    "attention_dropout": 0.0,
                    "num_experts": 8,
                    "num_experts_per_tok": 2,
                },
            },
            "code2wav_config": {
                "vocab_size": 1024,
                "hidden_size": 4096,
                "intermediate_size": 11008,
                "num_hidden_layers": 32,
                "num_attention_heads": 32,
                "num_key_value_heads": 4,
                "hidden_act": "silu",
                "max_position_embeddings": 32768,
                "initializer_range": 0.02,
                "rms_norm_eps": 1e-6,
                "use_cache": True,
                "rope_theta": 10000.0,
                "rope_scaling": None,
                "attention_bias": False,
                "attention_dropout": 0.0,
                "num_experts": 8,
                "num_experts_per_tok": 2,
            },
            "enable_audio_output": True,
            "im_start_token_id": 151644,
            "im_end_token_id": 151645,
            "tts_pad_token_id": 151671,
            "tts_bos_token_id": 151672,
            "tts_eos_token_id": 151673,
            "system_token_id": 8948,
            "user_token_id": 872,
            "assistant_token_id": 77091,
        },
    },
}
