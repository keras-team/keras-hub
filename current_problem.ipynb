{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceef28f5-6544-41de-9a02-b26e0256a4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import keras\n",
    "import keras_hub\n",
    "import math\n",
    "import numpy as np\n",
    "import PIL\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679b5162-7da7-4352-acb9-5244d568f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define presets\n",
    "PRESET_MAP = {\n",
    "    \"enet_b0_ra\": \"timm/efficientnet_b0.ra_in1k\",\n",
    "    \"enet_b1_ft\": \"timm/efficientnet_b1.ft_in1k\",\n",
    "    \"enet_b1_pruned\": \"timm/efficientnet_b1_pruned.in1k\",\n",
    "    \"enet_b2_ra\": \"timm/efficientnet_b2.ra_in1k\",\n",
    "    \"enet_b2_pruned\": \"timm/efficientnet_b2_pruned.in1k\",\n",
    "    \"enet_b3_ra2\": \"timm/efficientnet_b3.ra2_in1k\",\n",
    "    \"enet_b3_pruned\": \"timm/efficientnet_b3_pruned.in1k\",\n",
    "    \"enet_b4_ra2\": \"timm/efficientnet_b4.ra2_in1k\",\n",
    "    \"enet_b5_sw\": \"timm/efficientnet_b5.sw_in12k\",\n",
    "    \"enet_b5_sw_ft\": \"timm/efficientnet_b5.sw_in12k_ft_in1k\",\n",
    "    \"enet_el_ra\": \"timm/efficientnet_el.ra_in1k\",\n",
    "    \"enet_el_pruned\": \"timm/efficientnet_el_pruned.in1k\",\n",
    "    \"enet_em_ra2\": \"timm/efficientnet_em.ra2_in1k\",\n",
    "    \"enet_es_ra\": \"timm/efficientnet_es.ra_in1k\",\n",
    "    \"enet_es_pruned\": \"timm/efficientnet_es_pruned.in1k\",\n",
    "    \"enet_b0_ra4_e3600_r224\": \"timm/efficientnet_b0.ra4_e3600_r224_in1k\",\n",
    "    \"enet_b1_ra4_e3600_r240\": \"timm/efficientnet_b1.ra4_e3600_r240_in1k\",\n",
    "    \"enet2_rw_m_agc\": \"timm/efficientnetv2_rw_m.agc_in1k\",\n",
    "    \"enet2_rw_s_ra2\": \"timm/efficientnetv2_rw_s.ra2_in1k\",\n",
    "    \"enet2_rw_t_ra2\": \"timm/efficientnetv2_rw_t.ra2_in1k\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf6d963-493d-486f-9ffe-b3b576c94461",
   "metadata": {},
   "outputs": [],
   "source": [
    "stackwise_kernel_sizes = [3, 3, 5, 3, 5, 5, 3]\n",
    "stackwise_num_repeats = [1, 2, 2, 3, 3, 4, 1]\n",
    "stackwise_input_filters = [32, 16, 24, 40, 80, 112, 192]\n",
    "stackwise_output_filters = [16, 24, 40, 80, 112, 192, 320]\n",
    "stackwise_expansion_ratios = [1, 6, 6, 6, 6, 6, 6]\n",
    "stackwise_strides = [1, 2, 2, 2, 1, 2, 1]\n",
    "stackwise_squeeze_and_excite_ratios = [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ccd40ad-2877-47ab-a4cf-0f9cd222f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience functions\n",
    "def channel_first_to_last(x):\n",
    "    return keras.ops.transpose(x, axes=(0, 2, 3, 1))\n",
    "\n",
    "def channel_last_to_first(x):\n",
    "    return keras.ops.transpose(x, axes=(0, 3, 1, 2))\n",
    "\n",
    "def keras_compute(x, layer, sublayer_names):\n",
    "    cur_res = False\n",
    "    for name in sublayer_names:\n",
    "        sub_layer = layer.get_layer(name)\n",
    "        if name.endswith(\"se_squeeze\"):\n",
    "            se = sub_layer(x)\n",
    "        elif name.endswith(\"se_reshape\") or name.endswith(\"se_reduce\") or name.endswith(\"se_expand\"):\n",
    "            se = sub_layer(se)\n",
    "        elif name.endswith(\"se_excite\"):\n",
    "            x = sub_layer([x, se])\n",
    "        elif name.endswith(\"add\"):\n",
    "            x = sub_layer([x, res])\n",
    "            cur_res = False\n",
    "        # For potential residual computations\n",
    "        elif name.endswith(\"expand_conv\"):\n",
    "            res = x\n",
    "            cur_res = True\n",
    "            x = sub_layer(x)\n",
    "        elif name.endswith(\"dwconv_pad\"):\n",
    "            if not cur_res:\n",
    "                res = x\n",
    "                cur_res = True\n",
    "            x = sub_layer(x)\n",
    "        else:\n",
    "            x = sub_layer(x)\n",
    "    return x\n",
    "\n",
    "def pt_compute(x, modules):\n",
    "    for module in modules:\n",
    "        x = module(x)\n",
    "    return x\n",
    "\n",
    "def compare_tensors(keras_tensor, timm_tensor, atol=1e-8):\n",
    "    return np.allclose(keras_tensor, channel_first_to_last(timm_tensor.detach().numpy()), atol)\n",
    "\n",
    "def compare_conv2D_kernels(keras_conv2D, pt_conv2D, atol=1e-8):\n",
    "    return np.allclose(np.transpose(pt_conv2D.weight.detach().numpy(), (2, 3, 1, 0)), keras_conv2D.get_weights()[0], atol)\n",
    "\n",
    "def produce_layer_names(stack, block, expand_ratio, se_ratio, strides, filters_in, filters_out, dropout):\n",
    "    letter_identifier = chr(block + 97)\n",
    "    block_prefix = f\"block{stack+1}{letter_identifier}_\"\n",
    "    out = []\n",
    "    \n",
    "    if expand_ratio != 1:\n",
    "        out.append(block_prefix + \"expand_conv\")\n",
    "        out.append(block_prefix + \"expand_bn\")\n",
    "        out.append(block_prefix + \"expand_activation\")\n",
    "        \n",
    "    out.append(block_prefix + \"dwconv_pad\")\n",
    "    out.append(block_prefix + \"dwconv\")\n",
    "    out.append(block_prefix + \"dwconv_bn\")\n",
    "    out.append(block_prefix + \"dwconv_activation\")\n",
    "\n",
    "    if 0 < se_ratio <= 1:\n",
    "        out.append(block_prefix + \"se_squeeze\")\n",
    "        out.append(block_prefix + \"se_reshape\")\n",
    "        out.append(block_prefix + \"se_reduce\")\n",
    "        out.append(block_prefix + \"se_expand\")\n",
    "        out.append(block_prefix + \"se_excite\")\n",
    "\n",
    "    out.append(block_prefix + \"project\")\n",
    "    out.append(block_prefix + \"project_bn\")\n",
    "    out.append(block_prefix + \"project_activation\")\n",
    "\n",
    "    if strides == 1 and filters_in == filters_out:\n",
    "        if dropout > 0:\n",
    "            out.append(block_prefix + \"drop\")\n",
    "        out.append(block_prefix + \"add\")\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d68747db-f353-470b-9e2c-ba3eaa50d9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['block1a_dwconv_pad', 'block1a_dwconv', 'block1a_dwconv_bn', 'block1a_dwconv_activation', 'block1a_se_squeeze', 'block1a_se_reshape', 'block1a_se_reduce', 'block1a_se_expand', 'block1a_se_excite', 'block1a_project', 'block1a_project_bn', 'block1a_project_activation']\n",
      "['block2a_expand_conv', 'block2a_expand_bn', 'block2a_expand_activation', 'block2a_dwconv_pad', 'block2a_dwconv', 'block2a_dwconv_bn', 'block2a_dwconv_activation', 'block2a_se_squeeze', 'block2a_se_reshape', 'block2a_se_reduce', 'block2a_se_expand', 'block2a_se_excite', 'block2a_project', 'block2a_project_bn', 'block2a_project_activation']\n",
      "['block2b_expand_conv', 'block2b_expand_bn', 'block2b_expand_activation', 'block2b_dwconv_pad', 'block2b_dwconv', 'block2b_dwconv_bn', 'block2b_dwconv_activation', 'block2b_se_squeeze', 'block2b_se_reshape', 'block2b_se_reduce', 'block2b_se_expand', 'block2b_se_excite', 'block2b_project', 'block2b_project_bn', 'block2b_project_activation', 'block2b_add']\n",
      "['block3a_expand_conv', 'block3a_expand_bn', 'block3a_expand_activation', 'block3a_dwconv_pad', 'block3a_dwconv', 'block3a_dwconv_bn', 'block3a_dwconv_activation', 'block3a_se_squeeze', 'block3a_se_reshape', 'block3a_se_reduce', 'block3a_se_expand', 'block3a_se_excite', 'block3a_project', 'block3a_project_bn', 'block3a_project_activation']\n",
      "['block3b_expand_conv', 'block3b_expand_bn', 'block3b_expand_activation', 'block3b_dwconv_pad', 'block3b_dwconv', 'block3b_dwconv_bn', 'block3b_dwconv_activation', 'block3b_se_squeeze', 'block3b_se_reshape', 'block3b_se_reduce', 'block3b_se_expand', 'block3b_se_excite', 'block3b_project', 'block3b_project_bn', 'block3b_project_activation', 'block3b_add']\n",
      "['block4a_expand_conv', 'block4a_expand_bn', 'block4a_expand_activation', 'block4a_dwconv_pad', 'block4a_dwconv', 'block4a_dwconv_bn', 'block4a_dwconv_activation', 'block4a_se_squeeze', 'block4a_se_reshape', 'block4a_se_reduce', 'block4a_se_expand', 'block4a_se_excite', 'block4a_project', 'block4a_project_bn', 'block4a_project_activation']\n",
      "['block4b_expand_conv', 'block4b_expand_bn', 'block4b_expand_activation', 'block4b_dwconv_pad', 'block4b_dwconv', 'block4b_dwconv_bn', 'block4b_dwconv_activation', 'block4b_se_squeeze', 'block4b_se_reshape', 'block4b_se_reduce', 'block4b_se_expand', 'block4b_se_excite', 'block4b_project', 'block4b_project_bn', 'block4b_project_activation', 'block4b_add']\n",
      "['block4c_expand_conv', 'block4c_expand_bn', 'block4c_expand_activation', 'block4c_dwconv_pad', 'block4c_dwconv', 'block4c_dwconv_bn', 'block4c_dwconv_activation', 'block4c_se_squeeze', 'block4c_se_reshape', 'block4c_se_reduce', 'block4c_se_expand', 'block4c_se_excite', 'block4c_project', 'block4c_project_bn', 'block4c_project_activation', 'block4c_add']\n",
      "['block5a_expand_conv', 'block5a_expand_bn', 'block5a_expand_activation', 'block5a_dwconv_pad', 'block5a_dwconv', 'block5a_dwconv_bn', 'block5a_dwconv_activation', 'block5a_se_squeeze', 'block5a_se_reshape', 'block5a_se_reduce', 'block5a_se_expand', 'block5a_se_excite', 'block5a_project', 'block5a_project_bn', 'block5a_project_activation']\n",
      "['block5b_expand_conv', 'block5b_expand_bn', 'block5b_expand_activation', 'block5b_dwconv_pad', 'block5b_dwconv', 'block5b_dwconv_bn', 'block5b_dwconv_activation', 'block5b_se_squeeze', 'block5b_se_reshape', 'block5b_se_reduce', 'block5b_se_expand', 'block5b_se_excite', 'block5b_project', 'block5b_project_bn', 'block5b_project_activation', 'block5b_add']\n",
      "['block5c_expand_conv', 'block5c_expand_bn', 'block5c_expand_activation', 'block5c_dwconv_pad', 'block5c_dwconv', 'block5c_dwconv_bn', 'block5c_dwconv_activation', 'block5c_se_squeeze', 'block5c_se_reshape', 'block5c_se_reduce', 'block5c_se_expand', 'block5c_se_excite', 'block5c_project', 'block5c_project_bn', 'block5c_project_activation', 'block5c_add']\n",
      "['block6a_expand_conv', 'block6a_expand_bn', 'block6a_expand_activation', 'block6a_dwconv_pad', 'block6a_dwconv', 'block6a_dwconv_bn', 'block6a_dwconv_activation', 'block6a_se_squeeze', 'block6a_se_reshape', 'block6a_se_reduce', 'block6a_se_expand', 'block6a_se_excite', 'block6a_project', 'block6a_project_bn', 'block6a_project_activation']\n",
      "['block6b_expand_conv', 'block6b_expand_bn', 'block6b_expand_activation', 'block6b_dwconv_pad', 'block6b_dwconv', 'block6b_dwconv_bn', 'block6b_dwconv_activation', 'block6b_se_squeeze', 'block6b_se_reshape', 'block6b_se_reduce', 'block6b_se_expand', 'block6b_se_excite', 'block6b_project', 'block6b_project_bn', 'block6b_project_activation', 'block6b_add']\n",
      "['block6c_expand_conv', 'block6c_expand_bn', 'block6c_expand_activation', 'block6c_dwconv_pad', 'block6c_dwconv', 'block6c_dwconv_bn', 'block6c_dwconv_activation', 'block6c_se_squeeze', 'block6c_se_reshape', 'block6c_se_reduce', 'block6c_se_expand', 'block6c_se_excite', 'block6c_project', 'block6c_project_bn', 'block6c_project_activation', 'block6c_add']\n",
      "['block6d_expand_conv', 'block6d_expand_bn', 'block6d_expand_activation', 'block6d_dwconv_pad', 'block6d_dwconv', 'block6d_dwconv_bn', 'block6d_dwconv_activation', 'block6d_se_squeeze', 'block6d_se_reshape', 'block6d_se_reduce', 'block6d_se_expand', 'block6d_se_excite', 'block6d_project', 'block6d_project_bn', 'block6d_project_activation', 'block6d_add']\n",
      "['block7a_expand_conv', 'block7a_expand_bn', 'block7a_expand_activation', 'block7a_dwconv_pad', 'block7a_dwconv', 'block7a_dwconv_bn', 'block7a_dwconv_activation', 'block7a_se_squeeze', 'block7a_se_reshape', 'block7a_se_reduce', 'block7a_se_expand', 'block7a_se_excite', 'block7a_project', 'block7a_project_bn', 'block7a_project_activation']\n"
     ]
    }
   ],
   "source": [
    "def round_filters(\n",
    "    filters,\n",
    "    width_coefficient,\n",
    "    min_depth,\n",
    "    depth_divisor,\n",
    "    use_depth_divisor_as_min_depth,\n",
    "    cap_round_filter_decrease,\n",
    "):\n",
    "    \"\"\"Round number of filters based on depth multiplier.\n",
    "\n",
    "    Args:\n",
    "        filters: int, number of filters for Conv layer\n",
    "        width_coefficient: float, denotes the scaling coefficient of network\n",
    "            width\n",
    "        depth_divisor: int, a unit of network width\n",
    "        use_depth_divisor_as_min_depth: bool, whether to use depth_divisor as\n",
    "            the minimum depth instead of min_depth (as per v1)\n",
    "        max_round_filter_decrease: bool, whether to cap the decrease in the\n",
    "            number of filters this process produces (as per v1)\n",
    "\n",
    "    Returns:\n",
    "        int, new rounded filters value for Conv layer\n",
    "    \"\"\"\n",
    "    filters *= width_coefficient\n",
    "\n",
    "    if use_depth_divisor_as_min_depth:\n",
    "        min_depth = depth_divisor\n",
    "\n",
    "    new_filters = max(\n",
    "        min_depth,\n",
    "        int(filters + depth_divisor / 2) // depth_divisor * depth_divisor,\n",
    "    )\n",
    "\n",
    "    if cap_round_filter_decrease:\n",
    "        # Make sure that round down does not go down by more than 10%.\n",
    "        if new_filters < 0.9 * filters:\n",
    "            new_filters += depth_divisor\n",
    "\n",
    "    return int(new_filters)\n",
    "\n",
    "def round_repeats(repeats, depth_coefficient):\n",
    "    \"\"\"Round number of repeats based on depth multiplier.\n",
    "\n",
    "    Args:\n",
    "        repeats: int, number of repeats of efficientnet block\n",
    "        depth_coefficient: float, denotes the scaling coefficient of network\n",
    "            depth\n",
    "\n",
    "    Returns:\n",
    "        int, rounded repeats\n",
    "    \"\"\"\n",
    "    return int(math.ceil(depth_coefficient * repeats))\n",
    "\n",
    "\n",
    "width_coefficient = 1.0\n",
    "depth_coefficient = 1.0\n",
    "min_depth = None,\n",
    "depth_divisor = 8\n",
    "use_depth_divisor_as_min_depth = True\n",
    "cap_round_filter_decrease = True\n",
    "\n",
    "\n",
    "for i in range(len(stackwise_kernel_sizes)):\n",
    "    num_repeats = stackwise_num_repeats[i]\n",
    "    input_filters = stackwise_input_filters[i]\n",
    "    output_filters = stackwise_output_filters[i]\n",
    "\n",
    "    input_filters = round_filters(\n",
    "        filters=input_filters,\n",
    "        width_coefficient=width_coefficient,\n",
    "        min_depth=min_depth,\n",
    "        depth_divisor=depth_divisor,\n",
    "        use_depth_divisor_as_min_depth=use_depth_divisor_as_min_depth,\n",
    "        cap_round_filter_decrease=cap_round_filter_decrease,\n",
    "    )\n",
    "    output_filters = round_filters(\n",
    "        filters=output_filters,\n",
    "        width_coefficient=width_coefficient,\n",
    "        min_depth=min_depth,\n",
    "        depth_divisor=depth_divisor,\n",
    "        use_depth_divisor_as_min_depth=use_depth_divisor_as_min_depth,\n",
    "        cap_round_filter_decrease=cap_round_filter_decrease,\n",
    "    )\n",
    "\n",
    "    repeats = round_repeats(\n",
    "        repeats=num_repeats,\n",
    "        depth_coefficient=depth_coefficient,\n",
    "    )\n",
    "    strides = stackwise_strides[i]\n",
    "    squeeze_and_excite_ratio = stackwise_squeeze_and_excite_ratios[i]\n",
    "\n",
    "    for j in range(repeats):\n",
    "        \n",
    "        if j > 0:\n",
    "            strides = 1\n",
    "            input_filters = output_filters\n",
    "\n",
    "        print(produce_layer_names(i, j, stackwise_expansion_ratios[i], stackwise_squeeze_and_excite_ratios[i],\n",
    "                            strides, input_filters, output_filters, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e125e2a-215a-419f-a9c3-7448ef7d0446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create timm model & convert to keras_hub model\n",
    "timm_name = PRESET_MAP[\"enet_b0_ra\"]\n",
    "timm_model = timm.create_model(timm_name, pretrained=True)\n",
    "timm_model = timm_model.eval()\n",
    "keras_model = keras_hub.models.ImageClassifier.from_preset(\n",
    "    \"hf://\" + timm_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95acb71d-af12-4a60-ba51-1a41ce52564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://storage.googleapis.com/keras-cv/\"\n",
    "        \"models/paligemma/cow_beach_1.png\"\n",
    "\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\"\n",
    "\"https://i.imgur.com/mtbl1cr.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2fee253-e940-4599-8508-4405b6f1eba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658ms/step\n",
      "ðŸ”¶ Keras output: [-0.00153291  0.01410532 -0.09853543  0.19247465  0.2943132  -0.71479553\n",
      "  0.41454506  0.74578226  0.8629832   0.8470797 ]\n",
      "ðŸ”¶ TIMM output: [-0.3285119  -0.07352898 -0.81079614  1.2667956   0.49385935  0.13255954\n",
      "  0.78108     0.25159395  0.11376506 -1.6937063 ]\n",
      "ðŸ”¶ Keras label: 313\n",
      "ðŸ”¶ TIMM label: 345\n",
      "ðŸ”¶ Modeling difference: 0.7089012\n",
      "ðŸ”¶ Preprocessing difference: 1.1485839e-07\n"
     ]
    }
   ],
   "source": [
    "# Load example image & Preprocess\n",
    "file = keras.utils.get_file(\n",
    "        origin=(\n",
    "            \"https://storage.googleapis.com/keras-cv/\"\n",
    "            \"models/paligemma/cow_beach_1.png\"\n",
    "        )\n",
    "    )\n",
    "image = PIL.Image.open(file)\n",
    "batch = np.array([image])\n",
    "\n",
    "data_config = timm.data.resolve_model_data_config(timm_model)\n",
    "data_config[\"crop_pct\"] = 1.0  # Stop timm from cropping.\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "timm_preprocessed = transforms(image)\n",
    "timm_preprocessed = keras.ops.transpose(timm_preprocessed, axes=(1, 2, 0))\n",
    "timm_preprocessed = keras.ops.expand_dims(timm_preprocessed, 0)\n",
    "\n",
    "# Preprocess with Keras.\n",
    "batch = keras.ops.cast(batch, \"float32\")\n",
    "keras_preprocessed = keras_model.preprocessor(batch)\n",
    "\n",
    "# Call with Timm. Use the keras preprocessed image so we can keep modeling\n",
    "# and preprocessing comparisons independent.\n",
    "timm_batch = keras.ops.transpose(keras_preprocessed, axes=(0, 3, 1, 2))\n",
    "timm_batch = torch.from_numpy(np.array(timm_batch))\n",
    "timm_outputs = timm_model(timm_batch).detach().numpy()\n",
    "timm_label = np.argmax(timm_outputs[0])\n",
    "\n",
    "# Call with Keras.\n",
    "keras_outputs = keras_model.predict(batch)\n",
    "keras_label = np.argmax(keras_outputs[0])\n",
    "\n",
    "print(\"ðŸ”¶ Keras output:\", keras_outputs[0, :10])\n",
    "print(\"ðŸ”¶ TIMM output:\", timm_outputs[0, :10])\n",
    "print(\"ðŸ”¶ Keras label:\", keras_label)\n",
    "print(\"ðŸ”¶ TIMM label:\", timm_label)\n",
    "modeling_diff = np.mean(np.abs(keras_outputs - timm_outputs))\n",
    "print(\"ðŸ”¶ Modeling difference:\", modeling_diff)\n",
    "preprocessing_diff = np.mean(np.abs(keras_preprocessed - timm_preprocessed))\n",
    "print(\"ðŸ”¶ Preprocessing difference:\", preprocessing_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55fa7248-cc32-437e-80a7-ab014cbcb02f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mkeras_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/my_keras-nlp/keras_hub/src/models/task.py:342\u001b[0m, in \u001b[0;36mTask.summary\u001b[0;34m(self, line_length, positions, print_fn, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, ImageConverter):\n\u001b[1;32m    341\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage size: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 342\u001b[0m     info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mhighlight_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     add_layer(layer, info)\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, AudioConverter):\n",
      "File \u001b[0;32m~/git/my_keras-nlp/keras_hub/src/models/task.py:293\u001b[0m, in \u001b[0;36mTask.summary.<locals>.highlight_shape\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhighlight_shape\u001b[39m(shape):\n\u001b[0;32m--> 293\u001b[0m     highlighted \u001b[38;5;241m=\u001b[39m [highlight_number(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m shape]\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(highlighted) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3acd9a9d-990d-4619-9f31-5b546a76a49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5288548"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in timm_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c4ce996-1048-4b6c-aea9-c00b246e58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disection time\n",
    "# Take the input tensors and only go through the first layers\n",
    "keras_inter_tensor = keras_compute(keras_preprocessed, keras_model.backbone, [\"stem_conv_pad\", \"stem_conv\"])\n",
    "timm_inter_tensor = pt_compute(timm_batch, [timm_model.conv_stem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c287390-6a28-4122-bef8-096a2c3b195d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=1e-07, atol=1e-06\n\nMismatched elements: 4133 / 401408 (1.03%)\nMax absolute difference: 6.198883e-06\nMax relative difference: 0.08169387\n x: array([[[[-1.568060e+00, -2.120042e+00, -3.686755e-01, ...,\n           7.063465e-01,  7.547081e-02, -5.708362e+00],\n         [-1.712825e+00, -8.447712e-03, -5.333350e-01, ...,...\n y: array([[[[-1.568060e+00, -2.120042e+00, -3.686756e-01, ...,\n           7.063465e-01,  7.547063e-02, -5.708363e+00],\n         [-1.712824e+00, -8.447831e-03, -5.333350e-01, ...,...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_allclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeras_inter_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_first_to_last\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimm_inter_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/keras_migration/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/keras_migration/lib/python3.10/site-packages/numpy/testing/_private/utils.py:797\u001b[0m, in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf, strict)\u001b[0m\n\u001b[1;32m    793\u001b[0m         err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remarks)\n\u001b[1;32m    794\u001b[0m         msg \u001b[38;5;241m=\u001b[39m build_err_msg([ox, oy], err_msg,\n\u001b[1;32m    795\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39mverbose, header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m    796\u001b[0m                             names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m), precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[0;32m--> 797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=1e-07, atol=1e-06\n\nMismatched elements: 4133 / 401408 (1.03%)\nMax absolute difference: 6.198883e-06\nMax relative difference: 0.08169387\n x: array([[[[-1.568060e+00, -2.120042e+00, -3.686755e-01, ...,\n           7.063465e-01,  7.547081e-02, -5.708362e+00],\n         [-1.712825e+00, -8.447712e-03, -5.333350e-01, ...,...\n y: array([[[[-1.568060e+00, -2.120042e+00, -3.686756e-01, ...,\n           7.063465e-01,  7.547063e-02, -5.708363e+00],\n         [-1.712824e+00, -8.447831e-03, -5.333350e-01, ...,..."
     ]
    }
   ],
   "source": [
    "np.testing.assert_allclose(keras_inter_tensor, channel_first_to_last(timm_inter_tensor.detach().numpy()), atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a231d63-e315-4f25-bf33-a1e9165b0e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example if you want to grab a different intermediate tensor\n",
    "keras_inter_tensor = keras_compute(batch, keras_model.backbone, [\"stem_conv_pad\", \"stem_conv\", \"stem_bn\", \"stem_activation\",\n",
    "    \"block1a_dwconv_pad\", \"block1a_dwconv\", \"block1a_dwconv_bn\", \"block1a_dwconv_activation\", \"block1a_se_squeeze\", \"block1a_se_reshape\",\n",
    "    \"block1a_se_reduce\", \"block1a_se_expand\", \"block1a_se_excite\", \"block1a_project\", \"block1a_project_bn\", \"block1a_project_activation\"])\n",
    "timm_inter_tensor = pt_compute(timm_batch, [timm_model.conv_stem, timm_model.bn1, timm_model.blocks[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb5358-1c06-455c-9a88-dfca77668077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_migration",
   "language": "python",
   "name": "keras_migration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
